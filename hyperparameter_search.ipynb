{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will run replicates of a model and perform a random search of hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_handling\n",
    "import training_and_validation\n",
    "import hyperparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import importlib\n",
    "import glob\n",
    "\n",
    "from models import PD_CNN, ResNet, ResidualBlock, PD_LSTM\n",
    "import torch\n",
    "import training_and_validation\n",
    "from training_and_validation import loso_cross_validation, train, validate, cross_train, train_with_validation\n",
    "from result_visualization import run_chi_squared_test, plot_confusion_matrix\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import data_handling\n",
    "import models\n",
    "import result_visualization\n",
    "import random\n",
    "import hyperparam_tuning\n",
    "import os\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find training data, make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the device to cuda:0 \n",
    "if torch.cuda.is_available():  \n",
    "  device = \"cuda:0\" \n",
    "else:  \n",
    "  device = \"cpu\" \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please specify where you keep your training dataset\n",
    "training_data_src =  './Data/UNM/whole_dataset/'\n",
    "\n",
    "############ create list of subject numbers to leave out ###############################\n",
    "files = glob.glob(training_data_src + '*.csv')\n",
    "leave_one_out_list = []\n",
    "for file in files:  \n",
    "  if platform=='win32':\n",
    "    leave_one_out_list.append(file.split('\\\\')[-1])#.split('_')[1]) #remove hashtags to return to UNM dataset\n",
    "  elif platform=='linux' or platform=='linux2' or platform.startswith('darwin'):\n",
    "    leave_one_out_list.append(file.split('/')[-1])\n",
    "  else:\n",
    "    assert ValueError, 'operating system not identified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making a custom Dataset\n",
      "there are this many items in the list of data  118\n",
      "there are this many items in the list of labels  118\n",
      "The length of the lists of channels means and stds is  60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#make training dataset\n",
    "if device == 'cuda:0':\n",
    "    print('making a TensorDataset')\n",
    "    training_dataset = data_handling.make_data_into_tensor(data_path=training_data_src, device=device, )\n",
    "else:\n",
    "    print('making a custom Dataset')\n",
    "    training_dataset = data_handling.EEGDataset(data_path=training_data_src, chunk_size=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model and search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_model = 'Transformer'\n",
    "experiment_name = experiment_model+'_adjustable_pilot_hyperparameter_search'\n",
    "training_target_dir = './training_results/'+experiment_model+'/'+experiment_name+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------running replicate # 0 -------------------------\n",
      "hyperparameter configuration:  {'batch_size': 21, 'epochs': 2, 'learning_rate': 0.00029630094561443733, 'num_heads': 6, 'num_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting torch dataset\n",
      "train_dataloader 4\n",
      "val_dataloader 2\n",
      "in transformer, d_model: 60 n_head: 6 max_len: 5000 seq_len: 2500 ffn_hidden: 128 n_layers: 1 drop_prob: 0.1 details: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:46<02:19, 46.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting torch dataset\n",
      "train_dataloader 5\n",
      "val_dataloader 2\n",
      "in transformer, d_model: 60 n_head: 6 max_len: 5000 seq_len: 2500 ffn_hidden: 128 n_layers: 1 drop_prob: 0.1 details: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [01:31<01:31, 45.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting torch dataset\n",
      "train_dataloader 5\n",
      "val_dataloader 2\n",
      "in transformer, d_model: 60 n_head: 6 max_len: 5000 seq_len: 2500 ffn_hidden: 128 n_layers: 1 drop_prob: 0.1 details: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [02:05<00:40, 40.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting torch dataset\n",
      "train_dataloader 5\n",
      "val_dataloader 1\n",
      "in transformer, d_model: 60 n_head: 6 max_len: 5000 seq_len: 2500 ffn_hidden: 128 n_layers: 1 drop_prob: 0.1 details: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:40<00:00, 40.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total correct subject classifications:  0\n",
      "total incorrect subject classifications:  4\n",
      "total unsure subject classifications:  0\n",
      "total true postives (epochs) 0\n",
      "total false postives (epochs) 41\n",
      "total true negatives (epochs) 5\n",
      "total false negatives (epochs) 72\n",
      "----------------------------------------------------------------\n",
      "accuracy 0.0423728813559322  f1  0 sensitivity 0.0 specificity 0.10869565217391304\n",
      "./training_results/Transformer/Transformer_adjustable_pilot_hyperparameter_search/\n",
      "-----------------running replicate # 1 -------------------------\n",
      "hyperparameter configuration:  {'batch_size': 28, 'epochs': 2, 'learning_rate': 0.001309700938030553, 'num_heads': 4, 'num_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting torch dataset\n",
      "train_dataloader 3\n",
      "val_dataloader 2\n",
      "in transformer, d_model: 60 n_head: 4 max_len: 5000 seq_len: 2500 ffn_hidden: 128 n_layers: 1 drop_prob: 0.1 details: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:16<00:49, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting torch dataset\n",
      "train_dataloader 4\n",
      "val_dataloader 2\n",
      "in transformer, d_model: 60 n_head: 4 max_len: 5000 seq_len: 2500 ffn_hidden: 128 n_layers: 1 drop_prob: 0.1 details: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:34<00:34, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting torch dataset\n",
      "train_dataloader 4\n",
      "val_dataloader 2\n",
      "in transformer, d_model: 60 n_head: 4 max_len: 5000 seq_len: 2500 ffn_hidden: 128 n_layers: 1 drop_prob: 0.1 details: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:51<00:17, 17.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting torch dataset\n",
      "train_dataloader 4\n",
      "val_dataloader 1\n",
      "in transformer, d_model: 60 n_head: 4 max_len: 5000 seq_len: 2500 ffn_hidden: 128 n_layers: 1 drop_prob: 0.1 details: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:12<00:00, 18.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total correct subject classifications:  0\n",
      "total incorrect subject classifications:  4\n",
      "total unsure subject classifications:  0\n",
      "total true postives (epochs) 1\n",
      "total false postives (epochs) 40\n",
      "total true negatives (epochs) 6\n",
      "total false negatives (epochs) 71\n",
      "----------------------------------------------------------------\n",
      "accuracy 0.059322033898305086  f1  0.017699115044247787 sensitivity 0.013888888888888888 specificity 0.13043478260869565\n",
      "./training_results/Transformer/Transformer_adjustable_pilot_hyperparameter_search/\n",
      "-----------------running replicate # 2 -------------------------\n",
      "hyperparameter configuration:  {'batch_size': 30, 'epochs': 1, 'learning_rate': 0.0002367004488439419, 'num_heads': 2, 'num_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting torch dataset\n",
      "train_dataloader 3\n",
      "val_dataloader 2\n",
      "in transformer, d_model: 60 n_head: 2 max_len: 5000 seq_len: 2500 ffn_hidden: 128 n_layers: 6 drop_prob: 0.1 details: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:00<03:00, 60.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting torch dataset\n",
      "train_dataloader 3\n",
      "val_dataloader 2\n",
      "in transformer, d_model: 60 n_head: 2 max_len: 5000 seq_len: 2500 ffn_hidden: 128 n_layers: 6 drop_prob: 0.1 details: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [02:08<02:10, 65.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting torch dataset\n",
      "train_dataloader 3\n",
      "val_dataloader 2\n",
      "in transformer, d_model: 60 n_head: 2 max_len: 5000 seq_len: 2500 ffn_hidden: 128 n_layers: 6 drop_prob: 0.1 details: False\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(hyperparam_tuning)\n",
    "importlib.reload(training_and_validation)\n",
    "importlib.reload(models)\n",
    "import models\n",
    "import training_and_validation\n",
    "import hyperparam_tuning\n",
    "#run cross validation for N random configurations of hyperparameters\n",
    "hyperparam_tuning.perform_random_hyperparameter_search(training_dataset, leave_one_out_list, sample_size=60,\n",
    "                                                       learning_rate_min_max=(0.00001,0.01), batch_min_max=(2,32), \n",
    "                                                       epoch_min_max=(1,3), search_title=experiment_name, save_path=training_target_dir,\n",
    "                                                        model_type=experiment_model, device=device, rand_seed=5) #13 worked for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_EEG_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

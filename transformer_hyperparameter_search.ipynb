{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will run replicates of a model and perform a random search of hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_handling\n",
    "import training_and_validation\n",
    "import hyperparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import importlib\n",
    "import glob\n",
    "\n",
    "from models import PD_CNN, ResNet, ResidualBlock, PD_LSTM\n",
    "import torch\n",
    "import training_and_validation\n",
    "from training_and_validation import loso_cross_validation, train, validate, cross_train, train_with_validation\n",
    "from result_visualization import run_chi_squared_test, plot_confusion_matrix\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import data_handling\n",
    "import models\n",
    "import result_visualization\n",
    "import random\n",
    "import hyperparam_tuning\n",
    "import os\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find training data, make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the device to cuda:0 \n",
    "if torch.cuda.is_available():  \n",
    "  device = \"cuda:0\" \n",
    "else:  \n",
    "  device = \"cpu\" \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please specify where you keep your training dataset\n",
    "training_data_src =  './Data/UNM/small_subset/'\n",
    "\n",
    "############ create list of subject numbers to leave out ###############################\n",
    "files = glob.glob(training_data_src + '*.csv')\n",
    "leave_one_out_list = []\n",
    "for file in files:  \n",
    "  if platform=='win32':\n",
    "    leave_one_out_list.append(file.split('\\\\')[-1])#.split('_')[1]) #remove hashtags to return to UNM dataset\n",
    "  elif platform=='linux' or platform=='linux2' or platform.startswith('darwin'):\n",
    "    leave_one_out_list.append(file.split('/')[-1])\n",
    "  else:\n",
    "    assert ValueError, 'operating system not identified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making a custom Dataset\n",
      "there are this many items in the list of data  583\n",
      "there are this many items in the list of labels  583\n",
      "The length of the lists of channels means and stds is  60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#make training dataset\n",
    "if device == 'cuda:0':\n",
    "    print('making a TensorDataset')\n",
    "    training_dataset = data_handling.make_data_into_tensor(data_path=training_data_src, device=device, chunk_size=512)\n",
    "else:\n",
    "    print('making a custom Dataset')\n",
    "    training_dataset = data_handling.EEGDataset(data_path=training_data_src, chunk_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model and search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_model = 'Transformer'\n",
    "experiment_name = experiment_model+'adapting_search'\n",
    "training_target_dir = './training_results/'+experiment_model+'/'+experiment_name+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(hyperparam_tuning)\n",
    "importlib.reload(training_and_validation)\n",
    "importlib.reload(models)\n",
    "import models\n",
    "import training_and_validation\n",
    "import hyperparam_tuning\n",
    "#run cross validation for N random configurations of hyperparameters\n",
    "hyperparam_tuning.perform_random_hyperparameter_search(training_dataset, leave_one_out_list, sample_size=2,\n",
    "                                                       learning_rate_min_max=(0.00001,0.001), batch_min_max=(2,32), \n",
    "                                                       attention_blocks=6, heads=4, model_dim=60, seq_length=512,\n",
    "                                                       search_title=experiment_name, save_path=training_target_dir,\n",
    "                                                       model_type=experiment_model, device=device) #13 worked for one epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_EEG_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
